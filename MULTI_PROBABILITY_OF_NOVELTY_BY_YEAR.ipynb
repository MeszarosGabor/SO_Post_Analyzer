{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14be4a2a-ced3-46a3-9b50-bce43fc74ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cdc2e3f-8868-4d54-9653-2c43775f1773",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGES = [\n",
    "     #\"rust\",\n",
    "    \"python\",\n",
    "    \"javascript\",\n",
    "    \"java\",\n",
    "    \"ruby\",\n",
    "    \"r\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3448f2-6224-4c2f-98be-d7e417c489ee",
   "metadata": {},
   "source": [
    "# Probability of a random post being a novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0e8330-1101-4d32-9074-ebaa8a918bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing python...\n"
     ]
    }
   ],
   "source": [
    "novelty_plots = {}\n",
    "for language in LANGUAGES:\n",
    "    print(f\"Processing {language}...\")\n",
    "    path_to_lib = f\"data/results/{language}\"\n",
    "    \n",
    "    with open(f\"{path_to_lib}/{language}_{language}_post_stats.json\") as handle:\n",
    "        post_stats = json.load(handle)\n",
    "    sorted_post_stats = sorted(post_stats, key=lambda item:  datetime.datetime.strptime(item['date'], \"%Y-%m-%dT%H:%M:%S.%f\"))\n",
    "    \n",
    "    with open(f\"{path_to_lib}/{language}_pairs_first_dates.json\") as handle:\n",
    "        pairs_first_dates = json.load(handle)\n",
    "    \n",
    "    with open(f\"{path_to_lib}/{language}_all_pairs_dates.json\") as handle:\n",
    "        pairs_dates = json.load(handle)\n",
    "    \n",
    "    annual_post_count = collections.defaultdict(int)\n",
    "    annual_novelty_count = collections.defaultdict(int)\n",
    "    \n",
    "    for post_stat in tqdm.tqdm(sorted_post_stats):\n",
    "        year = post_stat[\"date\"][:4]\n",
    "        annual_post_count[year] += 1\n",
    "        novelty_count = 0\n",
    "        for imp1, imp2 in itertools.combinations(post_stat[\"imports\"], 2):\n",
    "            canonical_pair_name = \"|\".join(sorted([imp1, imp2]))\n",
    "            if pairs_first_dates[canonical_pair_name][\"id\"] == post_stat[\"id\"]:\n",
    "                novelty_count += 1\n",
    "        if novelty_count > 0:\n",
    "            annual_novelty_count[year] += 1\n",
    "\n",
    "    xs = list(annual_post_count.keys())\n",
    "    ys = [n/max(1, t) for n, t in zip(annual_novelty_count.values(), annual_post_count.values())]\n",
    "    novelty_plots[language] = ((xs, ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdca009-688b-46f4-b223-4cbdbb9fdb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1)\n",
    "f.set_figheight(10)\n",
    "f.set_figwidth(20)\n",
    "for lang in novelty_plots:\n",
    "    ax.plot(*novelty_plots[lang], \"-*\", label=lang)\n",
    "ax.legend(fontsize=12)\n",
    "ax.set_ylabel(\"Probability of a Post being a Novelty\", fontsize=14)\n",
    "ax.grid(alpha = 0.5)\n",
    "plt.xticks(rotation=70)\n",
    "ax.set_ylim(ymin=0)\n",
    "ax.set_xlim([\"2010\", \"2022\"])\n",
    "plt.xticks(size=15)\n",
    "plt.yticks(size=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2122392b-6c74-43c2-8c2f-98287dd8a6a2",
   "metadata": {},
   "source": [
    "# Probability of a random post being a valuable novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5793c5fa-85d8-4a0d-a07a-2eca89833164",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALUE_THRESHOLD_RATIO = 0.0001\n",
    "TIME_WINDOW = datetime.timedelta(days=365)\n",
    "\n",
    "value_plots = {}\n",
    "for language in LANGUAGES:\n",
    "    print(f\"Processing {language}...\")\n",
    "    path_to_lib = f\"data/results/{language}\"\n",
    "    \n",
    "    with open(f\"{path_to_lib}/{language}_{language}_post_stats.json\") as handle:\n",
    "        post_stats = json.load(handle)\n",
    "    sorted_post_stats = sorted(post_stats, key=lambda item:  datetime.datetime.strptime(item['date'], \"%Y-%m-%dT%H:%M:%S.%f\"))\n",
    "    \n",
    "    with open(f\"{path_to_lib}/{language}_pairs_first_dates.json\") as handle:\n",
    "        pairs_first_dates = json.load(handle)\n",
    "    \n",
    "    with open(f\"{path_to_lib}/{language}_all_pairs_dates.json\") as handle:\n",
    "        pairs_dates = json.load(handle)\n",
    "\n",
    "    with open(f\"{path_to_lib}/{language}_{language}_daily_post_stats.json\") as handle:\n",
    "        daily_post_stats = json.load(handle)\n",
    "    \n",
    "    annual_post_count = collections.defaultdict(int)\n",
    "    annual_value_count = {str(year): 0 for year in range(2008, 2024)}\n",
    "\n",
    "\n",
    "    # get cumulative_daily post_stats\n",
    "    cumulative_daily_post_stats = {}\n",
    "    runner = datetime.datetime(2008,1,1).date()\n",
    "    while runner < datetime.datetime(2024,1,1).date():\n",
    "        cumulative_daily_post_stats[runner] = 0\n",
    "        runner += datetime.timedelta(days=1)\n",
    "    summer = 0\n",
    "    for k in cumulative_daily_post_stats:\n",
    "        record = daily_post_stats.get(k.strftime(\"%Y-%m-%d\"), 0)\n",
    "        summer += record\n",
    "        cumulative_daily_post_stats[k] = summer\n",
    "\n",
    "    # Count valuable posts\n",
    "    for post_stat in tqdm.tqdm(sorted_post_stats):\n",
    "        year = post_stat[\"date\"][:4]\n",
    "        annual_post_count[year] += 1\n",
    "        for imp1, imp2 in itertools.combinations(post_stat[\"imports\"], 2):\n",
    "            canonical_pair_name = \"|\".join(sorted([imp1, imp2]))\n",
    "            if pairs_first_dates[canonical_pair_name][\"id\"] == post_stat[\"id\"]:\n",
    "                # novel post, we can assess if it is valuable\n",
    "                relevant_dates = [\n",
    "                    dt for dt in pairs_dates[canonical_pair_name]if (\n",
    "                        datetime.datetime.strptime(dt, \"%Y-%m-%d\") <\n",
    "                        datetime.datetime.strptime(pairs_first_dates[canonical_pair_name][\"date\"], \"%Y-%m-%d\") + TIME_WINDOW\n",
    "                        )\n",
    "                ]\n",
    "                posts_in_interval = (\n",
    "                    cumulative_daily_post_stats[\n",
    "                        min(\n",
    "                            datetime.datetime(2023,12,31),\n",
    "                            datetime.datetime.strptime(post_stat[\"date\"], \"%Y-%m-%dT%H:%M:%S.%f\") + datetime.timedelta(days=365),\n",
    "                        ).date()\n",
    "                    ] - \n",
    "                    cumulative_daily_post_stats[\n",
    "                        (datetime.datetime.strptime(post_stat[\"date\"], \"%Y-%m-%dT%H:%M:%S.%f\") - datetime.timedelta(days=1)).date()\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            if len(relevant_dates) / max(1, posts_in_interval) > VALUE_THRESHOLD_RATIO:\n",
    "                annual_value_count[year] += 1\n",
    "                break\n",
    "\n",
    "    xs = list(annual_post_count.keys())\n",
    "    ys = [n/max(1, t) for n, t in zip(annual_value_count.values(), annual_post_count.values())]\n",
    "    value_plots[language] = (xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a91cf6-7d1a-4a2a-bbf4-4cb568e95062",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1)\n",
    "f.set_figheight(10)\n",
    "f.set_figwidth(20)\n",
    "for lang in value_plots:\n",
    "    ax.plot(*value_plots[lang], \"-*\", label=lang)\n",
    "ax.legend()\n",
    "ax.set_ylabel(f\"Probability of a Post being a Valuable Novelty (value ratio: {100 * VALUE_THRESHOLD_RATIO}%)\")\n",
    "ax.grid(alpha = 0.5)\n",
    "plt.xticks(rotation=70)\n",
    "ax.set_ylim(ymin=0)\n",
    "ax.set_xlim([\"2010\", \"2022\"])\n",
    "plt.xticks(size=15)\n",
    "plt.yticks(size=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970d7381-f85a-40da-bbaf-b87e8e30032a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
